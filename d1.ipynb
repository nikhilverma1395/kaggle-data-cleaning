{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b91a74ba-85f4-486e-b5f9-d0898f0626bf",
        "_uuid": "6ac53f18b4f4ec0fc44348cedb5d1c319fa127c0"
      },
      "cell_type": "markdown",
      "source": "### All days of the challange:\n\n* [Day 1: Handling missing values](https://www.kaggle.com/rtatman/data-cleaning-challenge-handling-missing-values)\n* [Day 2: Scaling and normalization](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)\n* [Day 3: Parsing dates](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)\n* [Day 4: Character encodings](https://www.kaggle.com/rtatman/data-cleaning-challenge-character-encodings/)\n* [Day 5: Inconsistent Data Entry](https://www.kaggle.com/rtatman/data-cleaning-challenge-inconsistent-data-entry/)\n___\nWelcome to day 1 of the 5-Day Data Challenge! Today, we're going to be looking at how to deal with missing values. To get started, click the blue \"Fork Notebook\" button in the upper, right hand corner. This will create a private copy of this notebook that you can edit and play with. Once you're finished with the exercises, you can choose to make your notebook public to share with others. :)\n\n> **Your turn!** As we work through this notebook, you'll see some notebook cells (a block of either code or text) that has \"Your Turn!\" written in it. These are exercises for you to do to help cement your understanding of the concepts we're talking about. Once you've written the code to answer a specific question, you can run the code by clicking inside the cell (box with code in it) with the code you want to run and then hit CTRL + ENTER (CMD + ENTER on a Mac). You can also click in a cell and then click on the right \"play\" arrow to the left of the code. If you want to run all the code in your notebook, you can use the double, \"fast forward\" arrows at the bottom of the notebook editor.\n\nHere's what we're going to do today:\n\n* [Take a first look at the data](#Take-a-first-look-at-the-data)\n* [See how many missing data points we have](#See-how-many-missing-data-points-we-have)\n* [Figure out why the data is missing](#Figure-out-why-the-data-is-missing)\n* [Drop missing values](#Drop-missing-values)\n* [Filling in missing values](#Filling-in-missing-values)\n\nLet's get started!"
    },
    {
      "metadata": {
        "_cell_guid": "5cd5061f-ae30-4837-a53b-690ffd5c5830",
        "_uuid": "9d82bf13584b8e682962fbb96131f2447d741679"
      },
      "cell_type": "markdown",
      "source": "# Take a first look at the data\n________\n\nThe first thing we'll need to do is load in the libraries and datasets we'll be using. For today, I'll be using a dataset of events that occured in American Football games for demonstration, and you'll be using a dataset of building permits issued in San Francisco.\n\n> **Important!** Make sure you run this cell yourself or the rest of your code won't work!"
    },
    {
      "metadata": {
        "_cell_guid": "135a7804-b5f5-40aa-8657-4a15774e3666",
        "_uuid": "835cbe0834b935fb0fd40c75b9c39454836f4d5f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# read in all our data\nnfl_data = pd.read_csv(\"../input/nflplaybyplay2009to2016/NFL Play by Play 2009-2017 (v4).csv\")\nsf_permits = pd.read_csv(\"../input/building-permit-applications-data/Building_Permits.csv\")\n\n# set seed for reproducibility\nnp.random.seed(0) ",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (25,51) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (22,32) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "09b58d03-d34d-497a-b298-12a0ae962e3d",
        "_uuid": "53c84bf86149ac41b237633a1a79d6130d6a2cd4"
      },
      "cell_type": "markdown",
      "source": "The first thing I do when I get a new dataset is take a look at some of it. This lets me see that it all read in correctly and get an idea of what's going on with the data. In this case, I'm looking to see if I see any missing values, which will be reprsented with `NaN` or `None`."
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# look at a few rows of the nfl_data file. I can see a handful of missing data already!\nnfl_data.sample(5)",
      "execution_count": 2,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>GameID</th>\n      <th>Drive</th>\n      <th>qtr</th>\n      <th>down</th>\n      <th>time</th>\n      <th>TimeUnder</th>\n      <th>TimeSecs</th>\n      <th>PlayTimeDiff</th>\n      <th>SideofField</th>\n      <th>...</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>244485</th>\n      <td>2014-10-26</td>\n      <td>2014102607</td>\n      <td>18</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>00:39</td>\n      <td>1</td>\n      <td>939.0</td>\n      <td>12.0</td>\n      <td>TB</td>\n      <td>...</td>\n      <td>1.240299</td>\n      <td>0.225647</td>\n      <td>0.774353</td>\n      <td>0.245582</td>\n      <td>0.754418</td>\n      <td>0.225647</td>\n      <td>0.019935</td>\n      <td>-0.018156</td>\n      <td>0.038091</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>115340</th>\n      <td>2011-11-20</td>\n      <td>2011112000</td>\n      <td>22</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>06:47</td>\n      <td>7</td>\n      <td>407.0</td>\n      <td>44.0</td>\n      <td>OAK</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.056036</td>\n      <td>0.943964</td>\n      <td>0.042963</td>\n      <td>0.957037</td>\n      <td>0.943964</td>\n      <td>0.013073</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>68357</th>\n      <td>2010-11-14</td>\n      <td>2010111401</td>\n      <td>8</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>00:23</td>\n      <td>1</td>\n      <td>1823.0</td>\n      <td>0.0</td>\n      <td>CLE</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.365307</td>\n      <td>0.634693</td>\n      <td>0.384697</td>\n      <td>0.615303</td>\n      <td>0.634693</td>\n      <td>-0.019390</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>368377</th>\n      <td>2017-09-24</td>\n      <td>2017092405</td>\n      <td>24</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>08:48</td>\n      <td>9</td>\n      <td>528.0</td>\n      <td>8.0</td>\n      <td>CLE</td>\n      <td>...</td>\n      <td>1.075660</td>\n      <td>0.935995</td>\n      <td>0.064005</td>\n      <td>0.921231</td>\n      <td>0.078769</td>\n      <td>0.064005</td>\n      <td>0.014764</td>\n      <td>0.003866</td>\n      <td>0.010899</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>384684</th>\n      <td>2017-11-05</td>\n      <td>2017110505</td>\n      <td>11</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>09:15</td>\n      <td>10</td>\n      <td>2355.0</td>\n      <td>0.0</td>\n      <td>DEN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.928474</td>\n      <td>0.071526</td>\n      <td>0.934641</td>\n      <td>0.065359</td>\n      <td>0.071526</td>\n      <td>-0.006166</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 102 columns</p>\n</div>",
            "text/plain": "              Date      GameID  Drive  qtr  down   time  TimeUnder  TimeSecs  \\\n244485  2014-10-26  2014102607     18    3   1.0  00:39          1     939.0   \n115340  2011-11-20  2011112000     22    4   1.0  06:47          7     407.0   \n68357   2010-11-14  2010111401      8    2   NaN  00:23          1    1823.0   \n368377  2017-09-24  2017092405     24    4   1.0  08:48          9     528.0   \n384684  2017-11-05  2017110505     11    2   1.0  09:15         10    2355.0   \n\n        PlayTimeDiff SideofField   ...      yacEPA  Home_WP_pre  Away_WP_pre  \\\n244485          12.0          TB   ...    1.240299     0.225647     0.774353   \n115340          44.0         OAK   ...         NaN     0.056036     0.943964   \n68357            0.0         CLE   ...         NaN     0.365307     0.634693   \n368377           8.0         CLE   ...    1.075660     0.935995     0.064005   \n384684           0.0         DEN   ...         NaN     0.928474     0.071526   \n\n        Home_WP_post  Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  \\\n244485      0.245582      0.754418  0.225647  0.019935 -0.018156  0.038091   \n115340      0.042963      0.957037  0.943964  0.013073       NaN       NaN   \n68357       0.384697      0.615303  0.634693 -0.019390       NaN       NaN   \n368377      0.921231      0.078769  0.064005  0.014764  0.003866  0.010899   \n384684      0.934641      0.065359  0.071526 -0.006166       NaN       NaN   \n\n        Season  \n244485    2014  \n115340    2011  \n68357     2010  \n368377    2017  \n384684    2017  \n\n[5 rows x 102 columns]"
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "604ac3a4-b1d9-4264-b312-4bbeecdeec00",
        "_uuid": "03ce3b4afe87d98f777172c2c7be066a66a0b237"
      },
      "cell_type": "markdown",
      "source": "Yep, it looks like there's some missing values. What about in the sf_permits dataset?"
    },
    {
      "metadata": {
        "_cell_guid": "8dca377c-95be-40ec-87dc-61a8fca750e2",
        "_uuid": "e389495bb2e5d27ab632d5f3648ca1f912c94706",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# your turn! Look at a couple of rows from the sf_permits dataset. Do you notice any missing data?\nsf_permits.sample(5)\nsf_permits.describe(include='all')\n# your code goes here :)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "       Permit Number    Permit Type  Permit Type Definition  \\\ncount         198900  198900.000000                  198900   \nunique        181495            NaN                       8   \ntop     201602179765            NaN  otc alterations permit   \nfreq             101            NaN                  178844   \nmean             NaN       7.522323                     NaN   \nstd              NaN       1.457451                     NaN   \nmin              NaN       1.000000                     NaN   \n25%              NaN       8.000000                     NaN   \n50%              NaN       8.000000                     NaN   \n75%              NaN       8.000000                     NaN   \nmax              NaN       8.000000                     NaN   \n\n       Permit Creation Date   Block     Lot  Street Number  \\\ncount                198900  198900  198900  198900.000000   \nunique                 1291    4896    1055            NaN   \ntop              09/15/2017    3708     001            NaN   \nfreq                    413    1195   10114            NaN   \nmean                    NaN     NaN     NaN    1121.728944   \nstd                     NaN     NaN     NaN    1135.768948   \nmin                     NaN     NaN     NaN       0.000000   \n25%                     NaN     NaN     NaN     235.000000   \n50%                     NaN     NaN     NaN     710.000000   \n75%                     NaN     NaN     NaN    1700.000000   \nmax                     NaN     NaN     NaN    8400.000000   \n\n       Street Number Suffix Street Name Street Suffix      ...       \\\ncount                  2216      198900        196132      ...        \nunique                   18        1704            21      ...        \ntop                       A      Market            St      ...        \nfreq                   1501        5443        138358      ...        \nmean                    NaN         NaN           NaN      ...        \nstd                     NaN         NaN           NaN      ...        \nmin                     NaN         NaN           NaN      ...        \n25%                     NaN         NaN           NaN      ...        \n50%                     NaN         NaN           NaN      ...        \n75%                     NaN         NaN           NaN      ...        \nmax                     NaN         NaN           NaN      ...        \n\n        Existing Construction Type Existing Construction Type Description  \\\ncount                155534.000000                                 155534   \nunique                         NaN                                      5   \ntop                            NaN                         wood frame (5)   \nfreq                           NaN                                 113350   \nmean                      4.072878                                    NaN   \nstd                       1.585756                                    NaN   \nmin                       1.000000                                    NaN   \n25%                       3.000000                                    NaN   \n50%                       5.000000                                    NaN   \n75%                       5.000000                                    NaN   \nmax                       5.000000                                    NaN   \n\n       Proposed Construction Type Proposed Construction Type Description  \\\ncount               155738.000000                                 155738   \nunique                        NaN                                      5   \ntop                           NaN                         wood frame (5)   \nfreq                          NaN                                 114382   \nmean                     4.089529                                    NaN   \nstd                      1.578766                                    NaN   \nmin                      1.000000                                    NaN   \n25%                      3.000000                                    NaN   \n50%                      5.000000                                    NaN   \n75%                      5.000000                                    NaN   \nmax                      5.000000                                    NaN   \n\n       Site Permit Supervisor District Neighborhoods - Analysis Boundaries  \\\ncount         5359       197183.000000                              197175   \nunique           1                 NaN                                  41   \ntop              Y                 NaN      Financial District/South Beach   \nfreq          5359                 NaN                               21816   \nmean           NaN            5.538403                                 NaN   \nstd            NaN            2.887041                                 NaN   \nmin            NaN            1.000000                                 NaN   \n25%            NaN            3.000000                                 NaN   \n50%            NaN            6.000000                                 NaN   \n75%            NaN            8.000000                                 NaN   \nmax            NaN           11.000000                                 NaN   \n\n              Zipcode                                 Location     Record ID  \ncount   197184.000000                                   197200  1.989000e+05  \nunique            NaN                                    57604           NaN  \ntop               NaN  (37.79226164705184, -122.4034859571375)           NaN  \nfreq              NaN                                      554           NaN  \nmean     94115.500558                                      NaN  1.162048e+12  \nstd          9.270131                                      NaN  4.918215e+11  \nmin      94102.000000                                      NaN  1.293532e+10  \n25%      94109.000000                                      NaN  1.308567e+12  \n50%      94114.000000                                      NaN  1.371840e+12  \n75%      94122.000000                                      NaN  1.435000e+12  \nmax      94158.000000                                      NaN  1.498342e+12  \n\n[11 rows x 43 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Permit Number</th>\n      <th>Permit Type</th>\n      <th>Permit Type Definition</th>\n      <th>Permit Creation Date</th>\n      <th>Block</th>\n      <th>Lot</th>\n      <th>Street Number</th>\n      <th>Street Number Suffix</th>\n      <th>Street Name</th>\n      <th>Street Suffix</th>\n      <th>...</th>\n      <th>Existing Construction Type</th>\n      <th>Existing Construction Type Description</th>\n      <th>Proposed Construction Type</th>\n      <th>Proposed Construction Type Description</th>\n      <th>Site Permit</th>\n      <th>Supervisor District</th>\n      <th>Neighborhoods - Analysis Boundaries</th>\n      <th>Zipcode</th>\n      <th>Location</th>\n      <th>Record ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>198900</td>\n      <td>198900.000000</td>\n      <td>198900</td>\n      <td>198900</td>\n      <td>198900</td>\n      <td>198900</td>\n      <td>198900.000000</td>\n      <td>2216</td>\n      <td>198900</td>\n      <td>196132</td>\n      <td>...</td>\n      <td>155534.000000</td>\n      <td>155534</td>\n      <td>155738.000000</td>\n      <td>155738</td>\n      <td>5359</td>\n      <td>197183.000000</td>\n      <td>197175</td>\n      <td>197184.000000</td>\n      <td>197200</td>\n      <td>1.989000e+05</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>181495</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>1291</td>\n      <td>4896</td>\n      <td>1055</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>1704</td>\n      <td>21</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>41</td>\n      <td>NaN</td>\n      <td>57604</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>201602179765</td>\n      <td>NaN</td>\n      <td>otc alterations permit</td>\n      <td>09/15/2017</td>\n      <td>3708</td>\n      <td>001</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>Market</td>\n      <td>St</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>wood frame (5)</td>\n      <td>NaN</td>\n      <td>wood frame (5)</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>Financial District/South Beach</td>\n      <td>NaN</td>\n      <td>(37.79226164705184, -122.4034859571375)</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>101</td>\n      <td>NaN</td>\n      <td>178844</td>\n      <td>413</td>\n      <td>1195</td>\n      <td>10114</td>\n      <td>NaN</td>\n      <td>1501</td>\n      <td>5443</td>\n      <td>138358</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>113350</td>\n      <td>NaN</td>\n      <td>114382</td>\n      <td>5359</td>\n      <td>NaN</td>\n      <td>21816</td>\n      <td>NaN</td>\n      <td>554</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>7.522323</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1121.728944</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.072878</td>\n      <td>NaN</td>\n      <td>4.089529</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.538403</td>\n      <td>NaN</td>\n      <td>94115.500558</td>\n      <td>NaN</td>\n      <td>1.162048e+12</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>1.457451</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1135.768948</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.585756</td>\n      <td>NaN</td>\n      <td>1.578766</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.887041</td>\n      <td>NaN</td>\n      <td>9.270131</td>\n      <td>NaN</td>\n      <td>4.918215e+11</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>94102.000000</td>\n      <td>NaN</td>\n      <td>1.293532e+10</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>8.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>235.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>94109.000000</td>\n      <td>NaN</td>\n      <td>1.308567e+12</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>8.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>710.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>5.000000</td>\n      <td>NaN</td>\n      <td>5.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>94114.000000</td>\n      <td>NaN</td>\n      <td>1.371840e+12</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>8.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1700.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>5.000000</td>\n      <td>NaN</td>\n      <td>5.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.000000</td>\n      <td>NaN</td>\n      <td>94122.000000</td>\n      <td>NaN</td>\n      <td>1.435000e+12</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>8.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8400.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>5.000000</td>\n      <td>NaN</td>\n      <td>5.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.000000</td>\n      <td>NaN</td>\n      <td>94158.000000</td>\n      <td>NaN</td>\n      <td>1.498342e+12</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows Ã— 43 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "33656c2b-a74e-4b76-9af2-d7ecd518577b",
        "_uuid": "400b025f618cc76a39fec2537193f28ba1e49168"
      },
      "cell_type": "markdown",
      "source": "# See how many missing data points we have\n___\n\nOk, now we know that we do have some missing values. Let's see how many we have in each column. "
    },
    {
      "metadata": {
        "_cell_guid": "a69ac02d-197b-487b-a38f-2f853d208eed",
        "_uuid": "6dc0e32180c4a3bba003e7886faf126d93affadf",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# get the number of missing data points per column\nmissing_values_count = nfl_data.isnull().sum()\n\n# look at the # of missing points in the first ten columns\nmissing_values_count[0:10]",
      "execution_count": 4,
      "outputs": [
        {
          "data": {
            "text/plain": "Date                0\nGameID              0\nDrive               0\nqtr                 0\ndown            61154\ntime              224\nTimeUnder           0\nTimeSecs          224\nPlayTimeDiff      444\nSideofField       528\ndtype: int64"
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "84455c7e-6c63-4e08-a7b4-7520a61072f9",
        "_uuid": "054ba8782a7b0555336eddb90c985fb638beac4d"
      },
      "cell_type": "markdown",
      "source": "That seems like a lot! It might be helpful to see what percentage of the values in our dataset were missing to give us a better sense of the scale of this problem:"
    },
    {
      "metadata": {
        "_cell_guid": "fb77dd56-192e-48be-8181-2082985dd5a2",
        "_uuid": "d6e65ba197893f29d9dce0b0cd1c75017b60db09",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# how many total missing values do we have?\ntotal_cells = np.product(sf_permits.shape)\ntotal_missing = missing_values_count.sum()\n\n# percent of data that is missing\n(total_missing/total_cells) * 100",
      "execution_count": 5,
      "outputs": [
        {
          "data": {
            "text/plain": "24.87214126835169"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "31daa324-9215-4930-985c-01dee717b6b8",
        "_uuid": "3331fa42efa16f3db2e8e196411f351c5f8309f5"
      },
      "cell_type": "markdown",
      "source": "Wow, almost a quarter of the cells in this dataset are empty! In the next step, we're going to take a closer look at some of the columns with missing values and try to figure out what might be going on with them."
    },
    {
      "metadata": {
        "_cell_guid": "f20a9474-41ee-4ecd-a2f4-1ab147fc8655",
        "_uuid": "64487760aa1afaaa8b8a4d1f95206773759db101",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# your turn! Find out what percent of the sf_permits dataset is missing\n# how many total missing values do we have?\ntotal_cells = np.product(sf_permits.shape)\ntotal_missing = sf_permits.isnull().sum().sum()\n\n# percent of data that is missing\n(total_missing/total_cells) * 100",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "26.26002315058403"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "62b9f021-5b80-43e2-bf60-8e0d5e22d572",
        "_uuid": "032a618abb98a28e60ab84376cf21402178f995d"
      },
      "cell_type": "markdown",
      "source": "# Figure out why the data is missing\n____\n \nThis is the point at which we get into the part of data science that I like to call \"data intution\", by which I mean \"really looking at your data and trying to figure out why it is the way it is and how that will affect your analysis\". It can be a frustrating part of data science, especially if you're newer to the field and don't have a lot of experience. For dealing with missing values, you'll need to use your intution to figure out why the value is missing. One of the most important question you can ask yourself to help figure this out is this:\n\n> **Is this value missing becuase it wasn't recorded or becuase it dosen't exist?**\n\nIf a value is missing becuase it doens't exist (like the height of the oldest child of someone who doesn't have any children) then it doesn't make sense to try and guess what it might be. These values you probalby do want to keep as NaN. On the other hand, if a value is missing becuase it wasn't recorded, then you can try to guess what it might have been based on the other values in that column and row. (This is called \"imputation\" and we'll learn how to do it next! :)\n\nLet's work through an example. Looking at the number of missing values in the nfl_data dataframe, I notice that the column `TimesSec` has a lot of missing values in it: "
    },
    {
      "metadata": {
        "_cell_guid": "77739e82-8d32-4374-84bf-a924b6065168",
        "_uuid": "b65aea6046964806e44422c057bce8bd7f8e59d5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# look at the # of missing points in the first ten columns\nmissing_values_count[0:10]",
      "execution_count": 8,
      "outputs": [
        {
          "data": {
            "text/plain": "Date                0\nGameID              0\nDrive               0\nqtr                 0\ndown            61154\ntime              224\nTimeUnder           0\nTimeSecs          224\nPlayTimeDiff      444\nSideofField       528\ndtype: int64"
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "1b17f4c9-dcab-4857-82f9-a2534e804c91",
        "_uuid": "5cff158285ab37a89b80dcc35d5c690cdb42d3a4"
      },
      "cell_type": "markdown",
      "source": " By looking at [the documentation](https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016), I can see that this column has information on the number of seconds left in the game when the play was made. This means that these values are probably missing because they were not recorded, rather than because they don't exist. So, it would make sense for us to try and guess what they should be rather than just leaving them as NA's.\n\nOn the other hand, there are other fields, like `PenalizedTeam` that also have lot of missing fields. In this case, though, the field is missing because if there was no penalty then it doesn't make sense to say *which* team was penalized. For this column, it would make more sense to either leave it empty or to add a third value like \"neither\" and use that to replace the NA's.\n\n> **Tip:** This is a great place to read over the dataset documentation if you haven't already! If you're working with a dataset that you've gotten from another person, you can also try reaching out to them to get more information.\n\nIf you're doing very careful data analysis, this is the point at which you'd look at each column individually to figure out the best strategy for filling those missing values. For the rest of this notebook, we'll cover some \"quick and dirty\" techniques that can help you with missing values but will probably also end up removing some useful information or adding some noise to your data.\n\n## Your turn!\n    \n* Look at the columns `Street Number Suffix` and `Zipcode` from the `sf_permits` datasets. Both of these contain missing values. Which, if either, of these are missing because they don't exist? Which, if either, are missing because they weren't recorded?"
    },
    {
      "metadata": {
        "_cell_guid": "ea022b62-6419-47e7-973e-c3e707e2795f",
        "_uuid": "3f72f46f2464c7cd12f5eb2a752746ce1cd0b5a7"
      },
      "cell_type": "markdown",
      "source": "# Drop missing values\n___\n\nIf you're in a hurry or don't have a reason to figure out why your values are missing, one option you have is to just remove any rows or columns that contain missing values. (Note: I don't generally recommend this approch for important projects! It's usually worth it to take the time to go through your data and really look at all the columns with missing values one-by-one to really get to know your dataset.)  \n\nIf you're sure you want to drop rows with missing values, pandas does have a handy function, `dropna()` to help you do this. Let's try it out on our NFL dataset!"
    },
    {
      "metadata": {
        "_cell_guid": "ad0ac9a2-2854-4bb7-8886-8eee7fad8756",
        "_uuid": "ad8ef7825ba9bce3472a47d7c5242a4522f14065",
        "trusted": true
      },
      "cell_type": "code",
      "source": "sf_permits.columns.values\n\nfor col in sf_permits.columns.values:\n    pc = sf_permits[col].isnull().sum()/sf_permits[col].shape[0]\n    if pc > 75:\n        sf_permits = sf_permits.drop([col],axis=1)\n        \nfor col in nfl_data.columns.values:\n    pc = nfl_data[col].isnull().sum()/nfl_data[col].shape[0]\n    if pc > 75:\n        nfl_data = nfl_data.drop([col],axis=1)\n",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(198900, 43)\n(407688, 102)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "e0545655-3d37-448b-ae56-2c7707cd805d",
        "_uuid": "33eb849e076d2a4d0c409f58d78b5f303879b1b3"
      },
      "cell_type": "markdown",
      "source": "(Oh dear, it looks like that's removed all our data! ðŸ˜± This is because every row in our dataset had at least one missing value. We might have better luck removing all the *columns* that have at least one missing value instead."
    },
    {
      "metadata": {
        "_cell_guid": "97709ad4-f7b8-4cd0-8911-56e14db904ae",
        "_uuid": "87c569672854fe23e1ee9376ef3115ba4712cbf5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(sf_permits.shape)\nprint(nfl_data.shape)",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "         Date      GameID  Drive  qtr  TimeUnder  ydstogo  ydsnet  \\\n0  2009-09-10  2009091000      1    1         15        0       0   \n1  2009-09-10  2009091000      1    1         15       10       5   \n2  2009-09-10  2009091000      1    1         15        5       2   \n3  2009-09-10  2009091000      1    1         14        8       2   \n4  2009-09-10  2009091000      1    1         14        8       2   \n\n   PlayAttempted  Yards.Gained  sp   ...    Timeout_Indicator  Timeout_Team  \\\n0              1            39   0   ...                    0          None   \n1              1             5   0   ...                    0          None   \n2              1            -3   0   ...                    0          None   \n3              1             0   0   ...                    0          None   \n4              1             0   0   ...                    0          None   \n\n   posteam_timeouts_pre HomeTimeouts_Remaining_Pre AwayTimeouts_Remaining_Pre  \\\n0                     3                          3                          3   \n1                     3                          3                          3   \n2                     3                          3                          3   \n3                     3                          3                          3   \n4                     3                          3                          3   \n\n   HomeTimeouts_Remaining_Post  AwayTimeouts_Remaining_Post  ExPoint_Prob  \\\n0                            3                            3           0.0   \n1                            3                            3           0.0   \n2                            3                            3           0.0   \n3                            3                            3           0.0   \n4                            3                            3           0.0   \n\n   TwoPoint_Prob  Season  \n0            0.0    2009  \n1            0.0    2009  \n2            0.0    2009  \n3            0.0    2009  \n4            0.0    2009  \n\n[5 rows x 41 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>GameID</th>\n      <th>Drive</th>\n      <th>qtr</th>\n      <th>TimeUnder</th>\n      <th>ydstogo</th>\n      <th>ydsnet</th>\n      <th>PlayAttempted</th>\n      <th>Yards.Gained</th>\n      <th>sp</th>\n      <th>...</th>\n      <th>Timeout_Indicator</th>\n      <th>Timeout_Team</th>\n      <th>posteam_timeouts_pre</th>\n      <th>HomeTimeouts_Remaining_Pre</th>\n      <th>AwayTimeouts_Remaining_Pre</th>\n      <th>HomeTimeouts_Remaining_Post</th>\n      <th>AwayTimeouts_Remaining_Post</th>\n      <th>ExPoint_Prob</th>\n      <th>TwoPoint_Prob</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>39</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15</td>\n      <td>10</td>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>-3</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 41 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "0e51b19b-c44d-4487-8417-725d2b911739",
        "_uuid": "e60a092d2799851aa725eadf28b197022a6b127f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "nfl_data = nfl_data.fillna(method = 'bfill', axis=0).fillna(0)\nnfl_data = sf_permits.fillna(method = 'bfill', axis=0).fillna(0)",
      "execution_count": 47,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f417c614-f77f-45eb-b16b-fdc0be936502",
        "_uuid": "bac84fee4ca849e54839c716c43dddfbb559954b"
      },
      "cell_type": "markdown",
      "source": "We've lost quite a bit of data, but at this point we have successfully removed all the `NaN`'s from our data. "
    },
    {
      "metadata": {
        "_cell_guid": "0fe94654-7dad-4e8d-bbbb-e65e2bb2f767",
        "_uuid": "8207912f74712835283f7e1b30dad0471ee2e1fc",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Your turn! Try removing all the rows from the sf_permits dataset that contain missing values. How many are left?\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7ec643e1-abba-4683-b794-a1924e657501",
        "_uuid": "f804c0448b18b6d411ddf8452d15abba8292fffa",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Now try removing all the columns with empty values. Now how much of your data is left?\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1dbe153d-7b30-4ad8-80ad-a4c7fb53928e",
        "_uuid": "eb1ef8d47d9ebed77c3d21eca24708708ed4d45f"
      },
      "cell_type": "markdown",
      "source": "# Filling in missing values automatically\n_____\n\nAnother option is to try and fill in the missing values. For this next bit, I'm getting a small sub-section of the NFL data so that it will print well."
    },
    {
      "metadata": {
        "_cell_guid": "76fd83fb-a6d9-4c03-8c94-a111ee529881",
        "_uuid": "e0944282c73a63513d5345689ddd6a9da0fc8547",
        "trusted": true
      },
      "cell_type": "code",
      "source": "sf_permits.describe()",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "         Permit Type  Street Number          Unit  Number of Existing Stories  \\\ncount  198900.000000  198900.000000  29479.000000               156116.000000   \nmean        7.522323    1121.728944     78.517182                    5.705773   \nstd         1.457451    1135.768948    326.981324                    8.613455   \nmin         1.000000       0.000000      0.000000                    0.000000   \n25%         8.000000     235.000000      0.000000                    2.000000   \n50%         8.000000     710.000000      0.000000                    3.000000   \n75%         8.000000    1700.000000      1.000000                    4.000000   \nmax         8.000000    8400.000000   6004.000000                   78.000000   \n\n       Number of Proposed Stories  Estimated Cost  Revised Cost  \\\ncount               156032.000000    1.608340e+05  1.928340e+05   \nmean                     5.745043    1.689554e+05  1.328562e+05   \nstd                      8.613284    3.630386e+06  3.584903e+06   \nmin                      0.000000    1.000000e+00  0.000000e+00   \n25%                      2.000000    3.300000e+03  1.000000e+00   \n50%                      3.000000    1.100000e+04  7.000000e+03   \n75%                      4.000000    3.500000e+04  2.870750e+04   \nmax                     78.000000    5.379586e+08  7.805000e+08   \n\n       Existing Units  Proposed Units       Plansets  \\\ncount   147362.000000   147989.000000  161591.000000   \nmean        15.666164       16.510950       1.274650   \nstd         74.476321       75.220444      22.407345   \nmin          0.000000        0.000000       0.000000   \n25%          1.000000        1.000000       0.000000   \n50%          1.000000        2.000000       2.000000   \n75%          4.000000        4.000000       2.000000   \nmax       1907.000000     1911.000000    9000.000000   \n\n       Existing Construction Type  Proposed Construction Type  \\\ncount               155534.000000               155738.000000   \nmean                     4.072878                    4.089529   \nstd                      1.585756                    1.578766   \nmin                      1.000000                    1.000000   \n25%                      3.000000                    3.000000   \n50%                      5.000000                    5.000000   \n75%                      5.000000                    5.000000   \nmax                      5.000000                    5.000000   \n\n       Supervisor District        Zipcode     Record ID  \ncount        197183.000000  197184.000000  1.989000e+05  \nmean              5.538403   94115.500558  1.162048e+12  \nstd               2.887041       9.270131  4.918215e+11  \nmin               1.000000   94102.000000  1.293532e+10  \n25%               3.000000   94109.000000  1.308567e+12  \n50%               6.000000   94114.000000  1.371840e+12  \n75%               8.000000   94122.000000  1.435000e+12  \nmax              11.000000   94158.000000  1.498342e+12  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Permit Type</th>\n      <th>Street Number</th>\n      <th>Unit</th>\n      <th>Number of Existing Stories</th>\n      <th>Number of Proposed Stories</th>\n      <th>Estimated Cost</th>\n      <th>Revised Cost</th>\n      <th>Existing Units</th>\n      <th>Proposed Units</th>\n      <th>Plansets</th>\n      <th>Existing Construction Type</th>\n      <th>Proposed Construction Type</th>\n      <th>Supervisor District</th>\n      <th>Zipcode</th>\n      <th>Record ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>198900.000000</td>\n      <td>198900.000000</td>\n      <td>29479.000000</td>\n      <td>156116.000000</td>\n      <td>156032.000000</td>\n      <td>1.608340e+05</td>\n      <td>1.928340e+05</td>\n      <td>147362.000000</td>\n      <td>147989.000000</td>\n      <td>161591.000000</td>\n      <td>155534.000000</td>\n      <td>155738.000000</td>\n      <td>197183.000000</td>\n      <td>197184.000000</td>\n      <td>1.989000e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>7.522323</td>\n      <td>1121.728944</td>\n      <td>78.517182</td>\n      <td>5.705773</td>\n      <td>5.745043</td>\n      <td>1.689554e+05</td>\n      <td>1.328562e+05</td>\n      <td>15.666164</td>\n      <td>16.510950</td>\n      <td>1.274650</td>\n      <td>4.072878</td>\n      <td>4.089529</td>\n      <td>5.538403</td>\n      <td>94115.500558</td>\n      <td>1.162048e+12</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.457451</td>\n      <td>1135.768948</td>\n      <td>326.981324</td>\n      <td>8.613455</td>\n      <td>8.613284</td>\n      <td>3.630386e+06</td>\n      <td>3.584903e+06</td>\n      <td>74.476321</td>\n      <td>75.220444</td>\n      <td>22.407345</td>\n      <td>1.585756</td>\n      <td>1.578766</td>\n      <td>2.887041</td>\n      <td>9.270131</td>\n      <td>4.918215e+11</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>94102.000000</td>\n      <td>1.293532e+10</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8.000000</td>\n      <td>235.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>3.300000e+03</td>\n      <td>1.000000e+00</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>94109.000000</td>\n      <td>1.308567e+12</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8.000000</td>\n      <td>710.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>1.100000e+04</td>\n      <td>7.000000e+03</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>6.000000</td>\n      <td>94114.000000</td>\n      <td>1.371840e+12</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.000000</td>\n      <td>1700.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.500000e+04</td>\n      <td>2.870750e+04</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>8.000000</td>\n      <td>94122.000000</td>\n      <td>1.435000e+12</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>8.000000</td>\n      <td>8400.000000</td>\n      <td>6004.000000</td>\n      <td>78.000000</td>\n      <td>78.000000</td>\n      <td>5.379586e+08</td>\n      <td>7.805000e+08</td>\n      <td>1907.000000</td>\n      <td>1911.000000</td>\n      <td>9000.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>11.000000</td>\n      <td>94158.000000</td>\n      <td>1.498342e+12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "527c8703-4b29-459d-af7d-5505da36016b",
        "_uuid": "f8cfe916904af3265d8ecc4f791f9f62e34ff458"
      },
      "cell_type": "markdown",
      "source": "We can use the Panda's fillna() function to fill in missing values in a dataframe for us. One option we have is to specify what we want the `NaN` values to be replaced with. Here, I'm saying that I would like to replace all the `NaN` values with 0."
    },
    {
      "metadata": {
        "_cell_guid": "c01ed989-8901-43c8-afa3-6ca36605dfb5",
        "_uuid": "77eac530ce398b8c13eb7886f86bce48fd997f34",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1103b725-c823-4f40-9bda-e97997856339",
        "_uuid": "bec603202c6bfaae7a49b4a4042f37019ad1d801"
      },
      "cell_type": "markdown",
      "source": "I could also be a bit more savvy and replace missing values with whatever value comes directly after it in the same column. (This makes a lot of sense for datasets where the observations have some sort of logical order to them.)"
    },
    {
      "metadata": {
        "_cell_guid": "90ddac9b-ee20-492e-b437-0519c97ca317",
        "_uuid": "afba99aa7897539e9a0af77dce03daab94d0ca68",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "980e5d67-7e9c-41a3-b17e-51d87e9da9cf",
        "_uuid": "1f8ac8b52f2933612e315f06a53185e164e6c5bc"
      },
      "cell_type": "markdown",
      "source": "Filling in missing values is also known as \"imputation\", and you can find more exercises on it [in this lesson, also linked under the \"More practice!\" section](https://www.kaggle.com/dansbecker/handling-missing-values). First, however, why don't you try replacing some of the missing values in the sf_permit dataset?"
    },
    {
      "metadata": {
        "_cell_guid": "da426397-7e17-40ce-a0d4-ca6d39e47498",
        "_uuid": "f7d403c19eaf31ee0a4e04b9e1119eda96a9f95c",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Your turn! Try replacing all the NaN's in the sf_permits data with the one that\n# comes directly after it and then replacing any remaining NaN's with 0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee",
        "_uuid": "52b0af56e3c77db96056e9acd785f8f435f7caf5"
      },
      "cell_type": "markdown",
      "source": "And that's it for today! If you have any questions, be sure to post them in the comments below or [on the forums](https://www.kaggle.com/questions-and-answers). \n\nRemember that your notebook is private by default, and in order to share it with other people or ask for help with it, you'll need to make it public. First, you'll need to save a version of your notebook that shows your current work by hitting the \"Commit & Run\" button. (Your work is saved automatically, but versioning your work lets you go back and look at what it was like at the point you saved it. It also let's you share a nice compiled notebook instead of just the raw code.) Then, once your notebook is finished running, you can go to the Settings tab in the panel to the left (you may have to expand it by hitting the [<] button next to the \"Commit & Run\" button) and setting the \"Visibility\" dropdown to \"Public\".\n\n# More practice!\n___\n\nIf you're looking for more practice handling missing values, check out these extra-credit\\* exercises:\n\n* [Handling Missing Values](https://www.kaggle.com/dansbecker/handling-missing-values): In this notebook Dan shows you several approaches to imputing missing data using scikit-learn's imputer. \n* Look back at the `Zipcode` column in the `sf_permits` dataset, which has some missing values. How would you go about figuring out what the actual zipcode of each address should be? (You might try using another dataset. You can search for datasets about San Fransisco on the [Datasets listing](https://www.kaggle.com/datasets).) \n\n\\* no actual credit is given for completing the challenge, you just learn how to clean data real good :P"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}